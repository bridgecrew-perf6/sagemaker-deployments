{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "region = sess.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "prefix = \"sagemaker-datasetprep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/le-scientifique/torchDatasets/raw/master/dbpedia_csv.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: dbpedia_csv/test.csv: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: dbpedia_csv/classes.txt: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: dbpedia_csv/train.csv: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: dbpedia_csv/readme.txt: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: dbpedia_csv: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: Exiting with failure status due to previous errors\n"
     ]
    }
   ],
   "source": [
    "!tar -xzf dbpedia_csv.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,\"E. D. Abbott Ltd\",\" Abbott of Farnham E D Abbott Limited was a British coachbuilding business based in Farnham Surrey trading under that name from 1929. A major part of their output was under sub-contract to motor vehicle manufacturers. Their business closed in 1972.\"\n",
      "1,\"Schwan-Stabilo\",\" Schwan-STABILO is a German maker of pens for writing colouring and cosmetics as well as markers and highlighters for office use. It is the world's largest manufacturer of highlighter pens Stabilo Boss.\"\n",
      "1,\"Q-workshop\",\" Q-workshop is a Polish company located in Poznań that specializes in designand production of polyhedral dice and dice accessories for use in various games (role-playing gamesboard games and tabletop wargames). They also run an online retail store and maintainan active forum community.Q-workshop was established in 2001 by Patryk Strzelewicz – a student from Poznań. Initiallythe company sold its products via online auction services but in 2005 a website and online store wereestablished.\"\n"
     ]
    }
   ],
   "source": [
    "!head dbpedia_csv/train.csv -n 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,\"Automatic Electric\",\" Automatic Electric Company (AE) was the largest of the manufacturing units of the Automatic Electric Group. It was a telephone equipment supplier for independent telephone companies in North America and also had a world-wide presence. With its line of automatic telephone exchanges it was also a long-term supplier of switching equipment to the Bell System starting in 1919.\"\n",
      "1,\"Tokyo Marui\",\" Tokyo Marui Co. Ltd (株式会社東京マルイ Kabushiki-gaisha Tōkyō Marui) is an airsoft gun manufacturer located in Adachi Tokyo Japan. They are best known for creating the AEG(Automatic electric gun). Its main market is Japan but third-party retailers sell in Hong Kong (PRC) Taiwan (ROC) South Korea East Asia and worldwide. Such is the popularity of its guns that the company has its own center for airsoft sport called Tokyo Marui BB Sports Field.\"\n"
     ]
    }
   ],
   "source": [
    "!grep -i \"automatic electric\"  dbpedia_csv/train.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company\n",
      "EducationalInstitution\n",
      "Artist\n",
      "Athlete\n",
      "OfficeHolder\n",
      "MeanOfTransportation\n",
      "Building\n",
      "NaturalPlace\n",
      "Village\n",
      "Animal\n",
      "Plant\n",
      "Album\n",
      "Film\n",
      "WrittenWork\n"
     ]
    }
   ],
   "source": [
    "!cat dbpedia_csv/classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 'Company', '2': 'EducationalInstitution', '3': 'Artist', '4': 'Athlete', '5': 'OfficeHolder', '6': 'MeanOfTransportation', '7': 'Building', '8': 'NaturalPlace', '9': 'Village', '10': 'Animal', '11': 'Plant', '12': 'Album', '13': 'Film', '14': 'WrittenWork'}\n"
     ]
    }
   ],
   "source": [
    "d_label = {}\n",
    "with open ('dbpedia_csv/classes.txt') as f:\n",
    "    for i, label in enumerate(f.readlines()):\n",
    "        d_label[str(i + 1)] = label.strip()\n",
    "print(d_label)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(row):\n",
    "    cur_row = []\n",
    "    label = f'__label__{d_label[row[0]]}'\n",
    "    cur_row.append(label)\n",
    "    cur_row.extend(nltk.word_tokenize(row[1].lower()))\n",
    "    cur_row.extend(nltk.word_tokenize(row[2].lower()))\n",
    "    return cur_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import csv\n",
    "\n",
    "def preprocess(input_file, output_file, keep=1):\n",
    "    all_rows = []\n",
    "    with open(input_file, 'r') as csvinfile:\n",
    "        csv_reader = csv.reader(csvinfile, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            all_rows.append(row)\n",
    "    shuffle(all_rows)\n",
    "    all_rows = all_rows[: int(keep * len(all_rows))]\n",
    "    pool = Pool(processes = multiprocessing.cpu_count())\n",
    "    transformed_rows = pool.map(transform_text, all_rows)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    with open(output_file, 'w') as csvoutfile:\n",
    "        csvwriter = csv.writer(csvoutfile, delimiter=' ', lineterminator='\\n')\n",
    "        csvwriter.writerows(transformed_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.91 s, sys: 1.42 s, total: 11.3 s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preprocess('dbpedia_csv/train.csv', 'dbpedia_csv/dbpedia.train', keep=0.2)\n",
    "preprocess('dbpedia_csv/test.csv', 'dbpedia_csv/dbpedia.validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__Company winceyco winceyco is an entertainment group specializing in education in the state of new jersey with an emphasis on musical assembly series for schools and churches . the limited liability company was founded by wincey terry a professional vocalist who has worked with industry notables like spike lee bill cosby tina turner and garrison keilor . the group travels throughout the new jersey region delivering about 100 performances annually .\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 dbpedia_csv/dbpedia.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811284229777.dkr.ecr.us-east-1.amazonaws.com/blazingtext:1\n"
     ]
    }
   ],
   "source": [
    "image=sagemaker.image_uris.retrieve(framework='blazingtext', \n",
    "                                    region=region, \n",
    "                                    version='1')\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = f's3://{bucket}/{prefix}/output'\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "            image,\n",
    "            role,\n",
    "            instance_count=1,\n",
    "            instance_type='ml.c5.2xlarge',\n",
    "            volume_size=30,\n",
    "            max_run=360000,\n",
    "            input_mode='File',\n",
    "            enable_sagemaker_metrics=True,\n",
    "            output_path=s3_output_location,\n",
    "            hyperparameters={\n",
    "                'mode': 'supervised',\n",
    "                'epochs': 20,\n",
    "                'min_count': 2,\n",
    "                'learning_rate': 0.05,\n",
    "                'vector_dim': 10,\n",
    "                'early_stopping': True,\n",
    "                'patience': 4,\n",
    "                'min_epochs': 5,\n",
    "                'word_ngrams': 2,\n",
    "            },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-104877823522/sagemaker-datasetprep/train\n",
      "s3://sagemaker-us-east-1-104877823522/sagemaker-datasetprep/validation\n",
      "2022-04-13 02:57:19 Starting - Starting the training job...\n",
      "2022-04-13 02:57:49 Starting - Preparing the instances for trainingProfilerReport-1649818639: InProgress\n",
      "......\n",
      "2022-04-13 02:58:49 Downloading - Downloading input data...\n",
      "2022-04-13 02:59:09 Training - Downloading the training image...\n",
      "2022-04-13 02:59:49 Training - Training image download completed. Training in progress.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[04/13/2022 02:59:41 WARNING 140024490346304] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[04/13/2022 02:59:41 WARNING 140024490346304] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[04/13/2022 02:59:41 INFO 140024490346304] nvidia-smi took: 0.025160551071166992 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[04/13/2022 02:59:41 INFO 140024490346304] Running single machine CPU BlazingText training using supervised mode.\u001b[0m\n",
      "\u001b[34mNumber of CPU sockets found in instance is  1\u001b[0m\n",
      "\u001b[34m[04/13/2022 02:59:41 INFO 140024490346304] Processing /opt/ml/input/data/train/dbpedia.train . File size: 35.027403831481934 MB\u001b[0m\n",
      "\u001b[34m[04/13/2022 02:59:41 INFO 140024490346304] Processing /opt/ml/input/data/validation/dbpedia.validation . File size: 21.88746166229248 MB\u001b[0m\n",
      "\u001b[34mRead 6M words\u001b[0m\n",
      "\u001b[34mNumber of words:  148966\u001b[0m\n",
      "\u001b[34mLoading validation data from /opt/ml/input/data/validation/dbpedia.validation\u001b[0m\n",
      "\u001b[34mLoaded validation data.\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 3\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0413  Progress: 17.47%  Million Words/sec: 20.03 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 4\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0385  Progress: 22.93%  Million Words/sec: 20.60 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 5\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.970457\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0356  Progress: 28.89%  Million Words/sec: 17.81 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 6\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.971829\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0329  Progress: 34.21%  Million Words/sec: 16.73 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 7\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.972914\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0301  Progress: 39.76%  Million Words/sec: 16.02 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 8\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.974243\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0273  Progress: 45.41%  Million Words/sec: 15.63 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 9\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.974471\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0245  Progress: 51.06%  Million Words/sec: 15.19 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 10\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.975114\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0217  Progress: 56.51%  Million Words/sec: 14.89 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 11\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.9754\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 12\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.975914\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0186  Progress: 62.87%  Million Words/sec: 14.09 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 13\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.976186\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0158  Progress: 68.38%  Million Words/sec: 13.96 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 14\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.976343\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0130  Progress: 73.95%  Million Words/sec: 13.82 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 15\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.976329\u001b[0m\n",
      "\u001b[34mValidation accuracy has not improved for last 1 epochs.\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0104  Progress: 79.17%  Million Words/sec: 13.83 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 16\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.976457\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0076  Progress: 84.73%  Million Words/sec: 13.76 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 17\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.9766\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0048  Progress: 90.32%  Million Words/sec: 13.72 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 18\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.976571\u001b[0m\n",
      "\u001b[34mValidation accuracy has not improved for last 1 epochs.\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0022  Progress: 95.62%  Million Words/sec: 13.73 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 19\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.976714\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 20\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.976643\u001b[0m\n",
      "\u001b[34mValidation accuracy has not improved for last 1 epochs.\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0000  Progress: 100.00%  Million Words/sec: 13.34 #####\u001b[0m\n",
      "\u001b[34mTraining finished.\u001b[0m\n",
      "\u001b[34mAverage throughput in Million words/sec: 13.34\u001b[0m\n",
      "\u001b[34mTotal training time in seconds: 9.34\u001b[0m\n",
      "\u001b[34m#train_accuracy: 0.9961\u001b[0m\n",
      "\u001b[34mNumber of train examples: 112000\u001b[0m\n",
      "\u001b[34m#validation_accuracy: 0.9767\u001b[0m\n",
      "\u001b[34mNumber of validation examples: 70000\u001b[0m\n",
      "\n",
      "2022-04-13 03:00:29 Uploading - Uploading generated training model\n",
      "2022-04-13 03:00:29 Completed - Training job completed\n",
      "Training seconds: 97\n",
      "Billable seconds: 97\n"
     ]
    }
   ],
   "source": [
    "train_channel = prefix + '/train'\n",
    "validation_channel = prefix + '/validation'\n",
    "\n",
    "sess.upload_data(path='dbpedia_csv/dbpedia.train', bucket=bucket, key_prefix=train_channel)\n",
    "sess.upload_data(path='dbpedia_csv/dbpedia.validation', bucket=bucket, key_prefix=validation_channel)\n",
    "\n",
    "s3_train_data = f's3://{bucket}/{train_channel}'\n",
    "s3_validation_data = f's3://{bucket}/{validation_channel}'\n",
    "print(s3_train_data)\n",
    "print(s3_validation_data)\n",
    "\n",
    "data_channels = {'train': s3_train_data, \n",
    "                 'validation': s3_validation_data}\n",
    "\n",
    "exp_datetime = strftime('%Y-%m-%d-%H-%M-%S', gmtime())\n",
    "jobname = f'dbpedia-blazingtext-{exp_datetime}'\n",
    "\n",
    "estimator.fit(inputs=data_channels,\n",
    "              job_name=jobname,\n",
    "              logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-104877823522/sagemaker-datasetprep/output/dbpedia-blazingtext-2022-04-13-02-57-19/output/model.tar.gz'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-104877823522/sagemaker-datasetprep/output/dbpedia-blazingtext-2022-04-13-02-57-19/output/model.tar.gz to dbpedia_csv/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {estimator.model_data} ./dbpedia_csv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "cd dbpedia_csv/\n",
    "tar -zxf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q sagemaker-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbpedia-text-classification experiment already exists! Reusing the existing experiment\n"
     ]
    }
   ],
   "source": [
    "experiment_name = 'dbpedia-text-classification'\n",
    "\n",
    "try:\n",
    "    experiment = Experiment.create(\n",
    "        experiment_name = experiment_name,\n",
    "        description = 'Training a text classification using dbpedia dataset.')\n",
    "except ClientError as e:\n",
    "    print(f'{experiment_name} experiment already exists! Reusing the existing experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: dbpedia-blazingtext-2022-04-13-04-27-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted training job dbpedia-blazingtext-2022-04-13-04-27-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: dbpedia-blazingtext-2022-04-13-04-27-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted training job dbpedia-blazingtext-2022-04-13-04-27-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: dbpedia-blazingtext-2022-04-13-04-27-12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted training job dbpedia-blazingtext-2022-04-13-04-27-12\n"
     ]
    }
   ],
   "source": [
    "for lr in [0.1, 0.01, 0.001]:\n",
    "    exp_datetime = strftime('%Y-%m-%d-%H-%M-%S', gmtime())\n",
    "    jobname = f'dbpedia-blazingtext-{exp_datetime}'\n",
    "    \n",
    "    # Create a new trial for the experiment\n",
    "    exp_trial = Trial.create(\n",
    "        experiment_name = experiment_name,\n",
    "        trial_name = jobname)\n",
    "    \n",
    "    experiment_config = {\n",
    "        'ExperimentName':experiment_name,\n",
    "        'TrialName': exp_trial.trial_name,\n",
    "        'TrialComponentDisplayName': 'Training'}\n",
    "    \n",
    "    estimator = sagemaker.estimator.Estimator(\n",
    "        image,\n",
    "        role,\n",
    "        instance_count=1,\n",
    "        instance_type='ml.c5.2xlarge',\n",
    "        volume_size=30,\n",
    "        max_run=360000,\n",
    "        input_mode='File',\n",
    "        enable_sagemaker_metrics=True,\n",
    "        output_path=s3_output_location,\n",
    "        hyperparameters={\n",
    "            'mode':'supervised',\n",
    "            'epochs':40,\n",
    "            'min_count':2,\n",
    "            'learning_rate':lr,\n",
    "            'vector_dim':10,\n",
    "            'early_stopping':True,\n",
    "            'patience':4,\n",
    "            'min_epochs':5,\n",
    "            'word_nggrams':2},        \n",
    "    )\n",
    "    \n",
    "    estimator.fit(\n",
    "        inputs = data_channels,\n",
    "        job_name=jobname,\n",
    "        experiment_config = experiment_config,\n",
    "        wait = False)\n",
    "    \n",
    "    print(f'Submitted training job {jobname}')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
